{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sample-topic-analyze.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuukimiyo/CanvasWater/blob/master/sample_topic_analyze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGxgiu6rDR25",
        "colab_type": "text"
      },
      "source": [
        "# はじめに\n",
        "\n",
        "LSA（潜在的意味理解）を用いて文章からTopic抽出する処理のサンプルプログラムです。\n",
        "\n",
        "\n",
        "日本語コーパスとして無料公開されているLivedoorニュースコーパスの個別カテゴリの全記事から、指定した数のトピック（話題）を抽出する処理を行います。\n",
        "\n",
        "\n",
        "【技術解説】<br />\n",
        "*   Livedoorニュースコーパス：Livedoorニュースの記事から公開に差し障りのある部分を削除し、一般公開されている日本語コーパスです\n",
        "*   潜在意味解析(LSA) ：「～特異値分解(SVD)から文書検索まで～( https://mieruca-ai.com/ai/lsa-lsi-svd/ )」\n",
        "*   コーパス：広義では分析に用いる文章セットの事をさす。プログラム内で使用された場合は特定のデータ構造を言う場合が多いので他人のコードを読む際は注意が必要です。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKmuUsHwZuyh",
        "colab_type": "text"
      },
      "source": [
        "# 使い方\n",
        "\n",
        "コードが記載された各セル（背景が灰色）をクリックし、[Shift]キー+[Enter]キーでセル内の処理を実行してください。処理が実行されると処理対象が次のセルに自動的に遷移するので、上記キーを繰り返し押して処理を進めてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8OmuL5iWYko",
        "colab_type": "text"
      },
      "source": [
        "# 謝辞\n",
        "\n",
        "このサンプルプログラムではクリエイティブコモンズライセンスの元に公開されているLivedoor-corpusを利用しています。<br />\n",
        "https://www.rondhuit.com/download.html\n",
        "\n",
        "貴重な日本語テキストコーパスを公開して頂いたNHN Japan株式会社およびプログラム中で使用している各種ライブラリ等の製作者に謝意を表します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJwVmAVVP2Um",
        "colab_type": "text"
      },
      "source": [
        "# 前処理\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Loggerの初期化、MeCabのインストールとLivedoorニュースコーパスのダウンロードなどを行います。<br />\n",
        "少々時間がかかるので時間に余裕のあるときに実行してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTV66TIuYrkH",
        "colab_type": "text"
      },
      "source": [
        "### Loggerを初期化\n",
        "\n",
        "各種ライブラリから出力されるLog情報を扱うためのLoggerをセットアップします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAB_PFBdcjJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loggerを初期化\n",
        "# Colaboratory上でloglevelを変更した場合、ランタイムの再起動が必要\n",
        "from logging import basicConfig, getLogger, INFO as LOGLEVEL\n",
        "basicConfig(level=LOGLEVEL, format='%(asctime)s(%(levelname)s) %(name)s: %(message)s', datefmt='%I:%M:%S')\n",
        "logger = getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3f2XdhLYyA6",
        "colab_type": "text"
      },
      "source": [
        "### MeCab＋Neologd をダウンロード＆インストール\n",
        "\n",
        "この処理には3～4分ほどの時間がかかります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxml6ffBRSmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MeCab + Neologd辞書のインストール\n",
        "# 処理に３～４分かかります！\n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab swig\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n\n",
        "\n",
        "# pipを実行\n",
        "!pip install mecab-python3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJwV4WlcWSb2",
        "colab_type": "text"
      },
      "source": [
        "### Livedoor-corpusをダウンロード\n",
        "Livedoorcorpusをダウンロードして解凍します。\n",
        "1分ほどの時間がかかります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub_MKNphXItb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Livedoorコーパスのダウンロード\n",
        "!wget http://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
        "    \n",
        " # Livedoorコーパスの解凍\n",
        "!tar xzf ldcc-20140209.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIV1X6iTX7De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 解凍結果を確認します。\n",
        "# dokujo-tsushinなどのLivedoorcorpusのカテゴリ名が並んでいれば成功です\n",
        "!ls -l ./text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-d3yAhPZMZP",
        "colab_type": "text"
      },
      "source": [
        "### その他前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLXB0knLbyUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gensimモジュールのimport時に要求されるモジュールを予めインストールします。\n",
        "!pip install pattern"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQbEp_OkdakQ",
        "colab_type": "text"
      },
      "source": [
        "# メイン処理\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WItSc8HWVI2O",
        "colab_type": "text"
      },
      "source": [
        "### ライブラリの読み込みと定数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT0Vqjtb3UT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 利用ライブラリの読み込み\n",
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import codecs\n",
        "import re\n",
        "\n",
        "import MeCab\n",
        "import pandas as pd\n",
        "\n",
        "from gensim import corpora, models, similarities\n",
        "\n",
        "# システム辞書としてNeologdを指定してMeCabをセットアップ\n",
        "tagger = MeCab.Tagger('-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd -Owakati -E\"\"')\n",
        "\n",
        "# 入力するテキストの文字コードを指定\n",
        "input_charset = \"utf-8\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d65LhGNtJsm",
        "colab_type": "text"
      },
      "source": [
        "### 処理対象のカテゴリを指定\n",
        "\n",
        "Livedoorニュースコーパスに含まれるカテゴリから一つ選んで指定します。<br />\n",
        "今回のサンプルでは独女通信を選んで指定していますが、もちろん変更しても構いません。\n",
        " - dokujo-tsushin (独女通信)\n",
        " - it-life-hack (ITライフハック)\n",
        " - kaden-channel (家電チャンネル)\n",
        " - livedoor-homme (livedoor HOMME)\n",
        " - movie-enter (MOVIE ENTER)\n",
        " - peachy (Peachy)\n",
        " - smax (エスマックス)\n",
        " - sports-watch (Sports Watch)\n",
        " - topic-news (トピックニュース)\n",
        " \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C5ifFesvOur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 読み込み対象のカテゴリ名を指定\n",
        "category_name = \"movie-enter\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnClPsoconSY",
        "colab_type": "text"
      },
      "source": [
        "### クリーン処理用関数の作成\n",
        "\n",
        "配布されているLivedoorコーパスには、日付や文字としての[◆]、URLなど分析の際にノイズとなる文字列が多く含まれています。<br />\n",
        "そういったノイズを取り除くための関数を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuuZ0IJUMR3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# クリーン関数を作成\n",
        "\n",
        "# 正規表現置き換えのためのパターンをコンパイルし、配列に格納する。\n",
        "# ここでいうコンパイルはC言語などのコンパイルとは違い、正規表現処理などを高速に行うためのPython独自のテクニックのこと\n",
        "ptns = []\n",
        "ptns.append(re.compile(r\"@pad_sexy\"))\n",
        "ptns.append(re.compile(r\"\\\\+n\")) # 改行\n",
        "ptns.append(re.compile(r\"[\\s]+\")) # スペース文字\n",
        "ptns.append(re.compile(r\"\\([^\\(]{1,5}\\)\")) # 顔文字\n",
        "ptns.append(re.compile(r\"#[!-~]+\")) # 「# + 記号」の記述を削除\n",
        "ptns.append(re.compile(r\"@[!-~]+\")) # 「@ + 記号」の記述を削除\n",
        "ptns.append(re.compile(r\"[○|●|□|■|△|▲|▽|▼|◆|◇|【|】|※|★|☆]\"))\n",
        "ptns.append(re.compile(r'(https?|ftp)(:\\/\\/[-_.!~*\\'()a-zA-Z0-9;\\/?:\\@&=+\\$,%#]+)')) # URLを削除\n",
        "ptns.append(re.compile(r'(\\d{4})-(\\d{2})-(\\d{2})[T|t](\\d{2}):(\\d{2}):(\\d{2})\\+(\\d{4})')) # システム形式の日付表現を削除\n",
        "\n",
        "# 全角->半角変換（のための変換表をあらかじめコンパイルしておく）\n",
        "zen_chars = \"\".join(chr(0xff01 + i) for i in range(94))\n",
        "han_chars = \"\".join(chr(0x21 + i) for i in range(94))\n",
        "zen2han = str.maketrans(zen_chars, han_chars)\n",
        "\n",
        "\n",
        "def cleanText(t):\n",
        "    \"\"\"入力された文字列にクリーン処理を実施して結果を返す\n",
        "    Args:\n",
        "        t (str): 元の文字列\n",
        "    Returns:\n",
        "        str: 整形後の文字列\n",
        "    \"\"\"\n",
        "    \n",
        "    # 前後の改行等削除\n",
        "    t = t.strip()\n",
        "    \n",
        "    # 全角を半角に\n",
        "    t = t.translate(zen2han)\n",
        "    \n",
        "    # アルファベットをすべて小文字に\n",
        "    t = t.lower()\n",
        "    \n",
        "    # 正規表現を用いて、分析の邪魔になる部分を削除する。\n",
        "    # 配列に格納された正規表現マッチの処理を逐次適用して文字列削除を行う。\n",
        "    for ptn in ptns:\n",
        "        t = ptn.sub(\"\", t)\n",
        "    \n",
        "    return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-04SSVQpFbY",
        "colab_type": "text"
      },
      "source": [
        "### Livedoorコーパスを読み込み、クリーン処理および分かち書きを実施\n",
        "\n",
        "入力対象のフォルダにはLivedoorコーパスとして、ブログの１つの記事が１つのファイルとして格納されています。\n",
        "各記事のテキストに対してクリーン処理を実施し、一つの記事が１行となる配列を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S9VtRgrd9Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 入力するLivedoorcorpusの記事テキストが格納されたフォルダへのパス\n",
        "input_dir = os.path.join(\".\", \"text\", category_name)\n",
        "\n",
        "# 読み込み対象のファイル一覧を取得\n",
        "all_files = glob.glob(\"{}/*.txt\".format(input_dir))\n",
        "\n",
        "# 一つずつファイルを読み込んで、それぞれのファイルについて一行ずつでクリーン処理を実施します\n",
        "# 今回は全て行を一旦配列に格納していますが、入力が膨大になる場合はメモリ効率を考慮した処理に変更する必要があります。\n",
        "\n",
        "input_lines = []\n",
        "for i, file_path in enumerate(all_files):\n",
        "    # ファイルリストから、個別のファイル名を取得し、ひとつづつ処理する\n",
        "    with codecs.open(file_path, 'r', encoding=input_charset) as f:\n",
        "        each_file_lines = []\n",
        "        for l in f.readlines():\n",
        "            l = cleanText(l)\n",
        "            if len(l) <= 3:\n",
        "                next;\n",
        "            \n",
        "            each_file_lines.append(l)\n",
        "            \n",
        "        # ファイル内の全行を読み込んだら、一行にして分析用の配列（input_lines）に追加します\n",
        "        input_lines.append(\"\".join(each_file_lines))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-WT6YAEt3ps",
        "colab_type": "text"
      },
      "source": [
        "### クリーン処理の結果に対して分かち書きを実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI97Duezp7WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 分かち書きを実施\n",
        "input_lines_wakati = []\n",
        "for l in input_lines:\n",
        "    \n",
        "    # 分かち書きを実施\n",
        "    l = tagger.parse(l)\n",
        "    \n",
        "    # 単語数が3つ以上の場合に、分析用配列(input_lines_wakati)に追加します。\n",
        "    if len(l) >= 3: # 単語数が3つ以下の記事があった場合はここで足切りする\n",
        "        input_lines_wakati.append(l.split(\" \"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDVHCPyEwO2W",
        "colab_type": "text"
      },
      "source": [
        "### 分かち書きの結果を表示\n",
        "確認のため、単語IDの配列の一部を表示します。<br />\n",
        "（この部分は実行しなくても問題ないです）<br />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cexMIBkKwTKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 変換結果の確認\n",
        "for i, line in enumerate(input_lines_wakati):\n",
        "    print(line)\n",
        "    if i > 10:\n",
        "        break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpFPBnb6QPKo",
        "colab_type": "text"
      },
      "source": [
        "## 辞書の作成\n",
        "\n",
        "単語配列を単語ID配列に変換するための辞書を作成するします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfTZJbMbfF1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 単語配列化したTweetを辞書化（単語番号に変換）するための辞書を作成\n",
        "dictionary = corpora.Dictionary(input_lines_wakati)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQHU3QwDQYr8",
        "colab_type": "text"
      },
      "source": [
        "## 単語ID配列への変換\n",
        "分かち書きの結果を、単語IDの配列に変換します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3VxiS98bO_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 上記辞書を用いて単語配列を単語番号配列に変換（この単語番号配列をCorpusと呼ぶ場合が多い）\n",
        "corpus = [dictionary.doc2bow(line) for line in input_lines_wakati]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-KLaUfOcuct",
        "colab_type": "text"
      },
      "source": [
        "### 変換結果の確認\n",
        "確認のため、単語IDの配列の一部を表示します。<br />\n",
        "（この部分は実行しなくても問題ないです）<br />\n",
        "<br />\n",
        "配列の中身は、(単語ID, 記事内での単語の出現数)となっています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxa5XIuFRtqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 変換結果の確認\n",
        "for i, row in enumerate(corpus):\n",
        "    print(row)\n",
        "    if i > 10:\n",
        "        break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-ogve6edVRd",
        "colab_type": "text"
      },
      "source": [
        "### 辞書の確認\n",
        "先の手順で作成した辞書オブジェクトは配列として単語IDを与えるとそのIDが指し示している単語を返します。<br />\n",
        "興味のある方は次のように単語IDを与えて単語を表示してみましょう。\n",
        "（この部分は実行しなくても問題ないです）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2KWn--XDQwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary[40]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiZ9ASw5i7Xn",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJEeP2d1Qexn",
        "colab_type": "text"
      },
      "source": [
        "## 各記事をベクトル化する\n",
        "\n",
        "どれだけ珍しい単語を使っているかを手掛かりにして、各記事のベクトル表現を得ます。\n",
        "\n",
        "（ここでのベクトルはスパースベクトルとして表現されています。興味のある方は「スパースベクトル」で検索してみてください）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJJs74fS3o_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 単語ID配列を用い、Tfidf重みを使ってベクトル化\n",
        "\n",
        "# tfidf重みを算出するためのモデルファイルを作成\n",
        "tfidf = models.TfidfModel(corpus)\n",
        "\n",
        "# モデルファイルを元に、ベクトル化を実施\n",
        "corpus_tfidf = tfidf[corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkzy_RF1jGeM",
        "colab_type": "text"
      },
      "source": [
        "### ベクトル化した結果を表示\n",
        "各単語IDに対して、tfidfによって算出された重みが付与されたデータが作成されています。<br />\n",
        "（この部分は実行しなくても問題ないです）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DCngLjjWPtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ベクトル化した結果を表示\n",
        "for i, row in enumerate(corpus_tfidf):\n",
        "    print(row)\n",
        "    if i > 10:\n",
        "        break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV8GWJcZWseH",
        "colab_type": "text"
      },
      "source": [
        "## トピック抽出を実行\n",
        "LSI(潜在的意味解析)を用いてトピックを抽出する処理です。<br />\n",
        "gensimというライブラリのLsiModelという関数を使用してトピックオブジェクトを作成しています。<br />\n",
        "関数の使い方は次の公式URLに詳しく書いてあります。<br />\n",
        "https://radimrehurek.com/gensim/models/lsimodel.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIclf8YIcD2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lsaによるトピックの抽出を実行\n",
        "lsi = models.LsiModel(corpus=corpus_tfidf, id2word=dictionary,\n",
        "                             num_topics=20, chunksize=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDjoCWVq6sXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lsi = models.LsiModel(corpus=corpus_tfidf, num_topics=20, chunksize=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiOKvZNbm2Fm",
        "colab_type": "text"
      },
      "source": [
        "## トピックの確認\n",
        "トピックオブジェクトから、show_topic()関数を用いて個別のトピックを抽出して表示しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UBlW1vhn9gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# トピックリストを作成\n",
        "for i in range(len(lsi.get_topics())):\n",
        "    each_topic_words = []\n",
        "    for w in lsi.show_topic(i):\n",
        "        each_topic_words.append(\"{}:{:.4f}\".format(dictionary[int(w[0])], w[1]))\n",
        "    print(\"topic {}: {}\".format(i, \", \".join(each_topic_words)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7j5LVYLpT7T",
        "colab_type": "text"
      },
      "source": [
        "以上でLivedoorニュースコーパスの特定カテゴリから、指定した数のトピック（話題）を抽出する処理は完了です。<br />\n",
        "次からは抽出したトピックから一つの話題を選び、その話題に近い記事を抽出する、別の処理を作成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_OQI8UbLdqE",
        "colab_type": "text"
      },
      "source": [
        "# 個別のトピックに関連する記事を抽出する\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "以降の処理はトピック分析だけでなく、文章ベクトルなど大量のベクトルから特定の特徴を表したベクトルを抽出する目的で汎用的に使用できる処理です。<br />\n",
        "例えば、特定の単語を含んだニュースを抽出するなどの目的にも使用することができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPns5Dr4FZAx",
        "colab_type": "text"
      },
      "source": [
        "### 対象とするトピックを選択"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9R7GFG51rzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# トピックリストから、対象とするトピックをトピック番号を指定して抽出\n",
        "target_topic = lsi.show_topic(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7osSSDr4GSod",
        "colab_type": "text"
      },
      "source": [
        "### 対象とするトピックを表示\n",
        "確認のため単語IDを単語に直して表示してみます<br />\n",
        "トピック分析などで使用する際は、ここで表示するトピックベクトルに該当するデータを自分で作成すればよいわけです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4be64bRjFlxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 選択したトピックを確認\n",
        "[(dictionary[int(t[0])], t[1]) for t in target_topic]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeC2fbHhHHMD",
        "colab_type": "text"
      },
      "source": [
        "### トピック関連記事の抽出\n",
        "全記事を対象に、トピックとの類似度（ベクトルのコサイン距離）を算出し、類似度リストを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DuaD8-kHJFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 全記事を対象に、トピックベクトルとのコサイン距離を取得する\n",
        "similarity_index = similarities.SparseMatrixSimilarity(corpus_tfidf, num_features = len(dictionary))\n",
        "similarity_scores = list(similarity_index[target_topic])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lm5DbVfQobM",
        "colab_type": "text"
      },
      "source": [
        "### 類似度リストを個別の記事に関連付ける\n",
        "類似度リストは記事と同じ順序でトピックベクトルとの距離が格納されている配列なので、本文データと紐づけた配列を作成して降順にソートします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF2DYW_b2Nup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# トピックとのコサイン距離、記事番号、記事本文、によるリストを作成する\n",
        "topic_scores = []\n",
        "for i, line in enumerate(input_lines):\n",
        "    topic_scores.append([similarity_scores[i], i, line])\n",
        "\n",
        "# 上記リストをコサイン距離の大きい順に並べ替える\n",
        "topic_scores = sorted(topic_scores, reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz8oNlIbREkF",
        "colab_type": "text"
      },
      "source": [
        "### 抽出結果を表示\n",
        "トピックとの関連度順なっているデータの先頭50件を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q1k_l40Qjum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, t in enumerate(topic_scores):\n",
        "    print(t)\n",
        "    if i > 50:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}